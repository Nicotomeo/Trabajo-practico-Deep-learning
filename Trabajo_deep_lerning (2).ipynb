{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install pytorch-lightning"
      ],
      "metadata": {
        "id": "kmbS5gi9UHru"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zIaAOP7N3aBU"
      },
      "outputs": [],
      "source": [
        "# Librerías\n",
        "import math\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "from pytorch_lightning import LightningModule, Trainer, seed_everything\n",
        "from pytorch_lightning.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from pytorch_lightning.loggers import CSVLogger\n",
        "\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "from typing import Dict, Optional\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "id": "0wuDJ8td6Bx7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Cargar y transformar el dataset\n",
        "df = pd.read_excel(\"facultad.xlsx\")\n",
        "df[\"Periodo\"] = pd.to_datetime(df[\"Periodo\"])\n",
        "df_raw = df.sort_values(\"Periodo\")\n",
        "\n",
        "df_raw['Periodo'] = (df_raw['Periodo'] + pd.offsets.MonthEnd(0)).dt.to_period('M').dt.to_timestamp('M')\n",
        "df_raw = df_raw.sort_values('Periodo')\n",
        "df_raw = df_raw[['Periodo','Moneda','Destino','Stage','Sum(DeudaPesif)']].copy()\n"
      ],
      "metadata": {
        "id": "4ry3HDII51Bk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Carga el dataset de la inflacion mensual argentina\n",
        "df_inf = pd.read_excel(\"Inflacion.xlsx\")\n",
        "if 'Periodo' in df_inf.columns:\n",
        "    df_inf['Periodo'] = pd.to_datetime(df_inf['Periodo'])\n",
        "    df_inf['Periodo'] = (df_inf['Periodo'] + pd.offsets.MonthEnd(0)).dt.to_period('M').dt.to_timestamp('M')\n",
        "else:\n",
        "    raise ValueError(\"Inflacion.xlsx debe tener una columna 'Periodo'.\")\n",
        "\n",
        "infl_col = None\n",
        "for cand in ['Inflacion', 'IPC', 'inflacion', 'ipc']:\n",
        "    if cand in df_inf.columns:\n",
        "        infl_col = cand\n",
        "        break\n",
        "if infl_col is None:\n",
        "    num_cols = [c for c in df_inf.columns if c != 'Periodo' and pd.api.types.is_numeric_dtype(df_inf[c])]\n",
        "    if not num_cols:\n",
        "        raise ValueError(\"No se encontró columna numérica de inflación en Inflacion.xlsx.\")\n",
        "    infl_col = num_cols[0]\n",
        "\n",
        "df_inf = df_inf[['Periodo', infl_col]].rename(columns={infl_col: 'inflacion'}).copy()\n",
        "df_inf = df_inf.sort_values('Periodo').drop_duplicates(subset=['Periodo'], keep='last').reset_index(drop=True)\n"
      ],
      "metadata": {
        "id": "P7gWq6-g6p0_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Filtramos los destinos a analizar.\n",
        "DESTINOS_SELECCIONADOS = [\n",
        "    ('Pesos', 'COMERCIAL CAP.DE TRABAJO'),\n",
        "    ('Pesos', 'COMERCIAL INVERSIONES'),\n",
        "    ('Pesos', 'INDIVIDUOS PERSONALES'),\n",
        "    ('Pesos', 'INDIVIDUOS VIVIENDA'),\n",
        "    ('Pesos', 'INDIVIDUOS TARJETAS'),\n",
        "    ('Dolares estadounidenses', 'COMERCIAL CAP.DE TRABAJO'),\n",
        "    ('Dolares estadounidenses', 'COMERCIAL INVERSIONES'),\n",
        "]"
      ],
      "metadata": {
        "id": "8o2gXc947bNC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Filtrar solo con las columnas que interesan\n",
        "cols = ['Periodo','Moneda','Destino','Stage','Sum(DeudaPesif)']\n",
        "df_raw = df_raw[cols].copy()\n",
        "\n",
        "# Crear una máscara para filtrar\n",
        "mask_destinos = df_raw[['Moneda','Destino']].apply(tuple, axis=1).isin(DESTINOS_SELECCIONADOS)\n",
        "df_sel = df_raw[mask_destinos].copy()\n",
        "\n",
        "# Se filtra el DataFrame original con la máscara\n",
        "total_mes = (\n",
        "    df_sel.groupby(['Moneda','Destino', pd.Grouper(key='Periodo', freq='M')])['Sum(DeudaPesif)']\n",
        "         .sum().rename('total_destino').reset_index()\n",
        ")\n",
        "\n",
        "# Se calcula el total de deuda por mes, moneda y destino. Luego se agrupa\n",
        "\n",
        "stage23_mes = (\n",
        "    df_sel[df_sel['Stage'].isin(['Stage 2','Stage 3'])]\n",
        "        .groupby(['Moneda','Destino', pd.Grouper(key='Periodo', freq='M')])['Sum(DeudaPesif)']\n",
        "        .sum().rename('stage23_destino').reset_index()\n",
        ")\n",
        "\n",
        "# Se calcula la deuda solo de Stage 2 y Stage 3 por mes, moneda y destino\n",
        "df_pct = total_mes.merge(stage23_mes, on=['Moneda','Destino','Periodo'], how='left')\n",
        "\n",
        "df_pct['stage23_destino'] = df_pct['stage23_destino'].fillna(0.0)\n",
        "\n",
        "# Se calcula el porcentaje que representa la deuda Stage 2-3 sobre el total\n",
        "df_pct['porcentaje'] = (df_pct['stage23_destino'] / df_pct['total_destino']).replace([np.inf, -np.inf], np.nan)\n",
        "\n",
        "df_pct = df_pct.sort_values(['Moneda','Destino','Periodo']).reset_index(drop=True)\n",
        "\n"
      ],
      "metadata": {
        "id": "Tst5nQqh7NHx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Regresores de calendario: mes como sin/cos (estacionalidad anual)\n",
        "\n",
        "def month_sin_cos(index: pd.DatetimeIndex) -> np.ndarray:\n",
        "    m = index.month.values\n",
        "    return np.vstack([np.sin(2*np.pi*m/12.0), np.cos(2*np.pi*m/12.0)]).T.astype(np.float32)\n",
        "\n",
        "class MinMaxScaler1D:\n",
        "    # Escalador simple 1D con protección ante valores no finitos\n",
        "    def fit(self, x: np.ndarray):\n",
        "        x = x[np.isfinite(x)]\n",
        "        self.min_ = float(np.min(x)) if len(x) else 0.0\n",
        "        self.max_ = float(np.max(x)) if len(x) else 1.0\n",
        "        self.range_ = self.max_ - self.min_ if self.max_ > self.min_ else 1.0\n",
        "        return self\n",
        "    def transform(self, x: np.ndarray):\n",
        "        return ((x - self.min_) / self.range_).astype(np.float32)\n",
        "    def inverse_transform(self, x: np.ndarray):\n",
        "        return (x * self.range_ + self.min_).astype(np.float32)\n",
        "\n",
        "def align_inflation_to_index(df_infl: pd.DataFrame, index: pd.DatetimeIndex) -> np.ndarray:\n",
        "    s = df_infl.set_index('Periodo')['inflacion'].sort_index()\n",
        "    s = s.reindex(index).ffill()\n",
        "    return s.values.astype(np.float32)\n",
        "\n",
        "    # Se convierte una serie y sus regresores en ventanas supervisadas\n",
        "    # Devuelve arrays listos para el DataModule\n",
        "def build_windows_with_regs(y: np.ndarray, regs: np.ndarray, idx: pd.DatetimeIndex, lookback: int, horizon: int):\n",
        "    X, Y, XR, YR, t_idx = [], [], [], [], []\n",
        "    T = len(y)\n",
        "\n",
        "    if T < lookback + horizon:\n",
        "        print(f\"[AVISO] Serie demasiado corta (T={T}) para lookback={lookback} y horizon={horizon}\")\n",
        "        return (\n",
        "            np.empty((0, lookback), dtype=np.float32),\n",
        "            np.empty((0, horizon), dtype=np.float32),\n",
        "            np.empty((0, lookback, regs.shape[1]), dtype=np.float32),\n",
        "            np.empty((0, horizon, regs.shape[1]), dtype=np.float32),\n",
        "            np.empty((0,), dtype='datetime64[ns]')\n",
        "        )\n",
        "\n",
        "    for t in range(lookback, T - horizon + 1):\n",
        "        if not (np.isfinite(y[t-lookback:t]).all() and np.isfinite(y[t:t+horizon]).all()):\n",
        "            continue\n",
        "        X.append(y[t-lookback:t])\n",
        "        Y.append(y[t:t+horizon])\n",
        "        XR.append(regs[t-lookback:t, :])\n",
        "        YR.append(regs[t:t+horizon, :])\n",
        "        t_idx.append(idx[t])\n",
        "\n",
        "    return (\n",
        "        np.array(X, np.float32),\n",
        "        np.array(Y, np.float32),\n",
        "        np.array(XR, np.float32),\n",
        "        np.array(YR, np.float32),\n",
        "        np.array(t_idx)\n",
        "    )"
      ],
      "metadata": {
        "id": "awVTn9U97zQc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Hiperparámetros principales del modelo y del entrenamiento:\n",
        "\n",
        "LOOKBACK    = 12\n",
        "H           = 6\n",
        "MAX_EPOCHS  = 120\n",
        "PATIENCE    = 15\n",
        "BATCH_SIZE  = 64\n",
        "\n",
        "HIDDEN_DIM  = 64\n",
        "NUM_LAYERS  = 2\n",
        "DROPOUT     = 0.1\n",
        "LR          = 1e-3\n",
        "NHEAD = 4  # cantidad de cabezas en el mecanismo de atención del Transformer"
      ],
      "metadata": {
        "id": "Ap6ULEEE81eK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class TSDataset(Dataset):\n",
        "    # Dataset con claves estándar para el forecaster\n",
        "    def __init__(self, X, Y, XR, YR):\n",
        "        self.X = X; self.Y = Y; self.XR = XR; self.YR = YR\n",
        "    def __len__(self): return len(self.X)\n",
        "    def __getitem__(self, idx):\n",
        "        x  = torch.tensor(self.X[idx])\n",
        "        y  = torch.tensor(self.Y[idx])\n",
        "        xr = torch.tensor(self.XR[idx])\n",
        "        yr = torch.tensor(self.YR[idx])\n",
        "        return {'x_demand': x.unsqueeze(-1), 'y_demand': y.unsqueeze(-1),\n",
        "                'x_regressors': xr, 'y_regressors': yr}\n",
        "\n",
        "class TSDataModule:\n",
        "    # Produce DataLoaders de train/val\n",
        "    def __init__(self, Xtr, Ytr, XRtr, YRtr, Xva, Yva, XRva, YRva, batch_size=64):\n",
        "        self.train_ds = TSDataset(Xtr, Ytr, XRtr, YRtr)\n",
        "        self.val_ds   = TSDataset(Xva, Yva, XRva, YRva)\n",
        "        self.batch_size = batch_size\n",
        "    def train_dataloader(self):\n",
        "        return DataLoader(self.train_ds, batch_size=self.batch_size, shuffle=True)\n",
        "    def val_dataloader(self):\n",
        "        return DataLoader(self.val_ds, batch_size=self.batch_size, shuffle=False)\n"
      ],
      "metadata": {
        "id": "GluMQM7x89ZW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Clase base para modelos de pronóstico con PyTorch Lightning.\n",
        "class BaseForecaster(LightningModule):\n",
        "    '''\n",
        "    Base Lightning forecaster (estilo clase).\n",
        "    Los modelos hijos deben implementar:\n",
        "      forward(x_demand, x_regressors=None, y_demand=None, y_regressors=None)\n",
        "    '''\n",
        "    def __init__(self, learning_rate: float = 1e-3):\n",
        "        super().__init__()\n",
        "        self.save_hyperparameters(logger=False)\n",
        "\n",
        "    def _common_step(self, batch: Dict[str, torch.Tensor], stage: str):\n",
        "        x     = batch['x_demand']\n",
        "        y     = batch['y_demand']\n",
        "        x_reg = batch.get('x_regressors', None)\n",
        "        y_reg = batch.get('y_regressors', None)\n",
        "        y_hat = self(x, x_regressors=x_reg, y_demand=y, y_regressors=y_reg)\n",
        "\n",
        "# Centraliza el cálculo de métricas (MSE y MAE) y la configuración del optimizador\n",
        "\n",
        "        mse = F.mse_loss(y_hat, y)\n",
        "        mae = F.l1_loss(y_hat, y)\n",
        "\n",
        "        self.log(f'{stage}_mse', mse, prog_bar=True, on_step=False, on_epoch=True)\n",
        "        self.log(f'{stage}_mae', mae, prog_bar=(stage != 'train'), on_step=False, on_epoch=True)\n",
        "        return {'loss': mse, 'mse': mse.detach(), 'mae': mae.detach()}\n",
        "\n",
        "    def training_step(self, batch: Dict[str, torch.Tensor], batch_idx: int) -> torch.Tensor:\n",
        "        return self._common_step(batch, 'train')['loss']\n",
        "\n",
        "    def validation_step(self, batch: Dict[str, torch.Tensor], batch_idx: int):\n",
        "        return self._common_step(batch, 'val')\n",
        "\n",
        "    def test_step(self, batch: Dict[str, torch.Tensor], batch_idx: int):\n",
        "        return self._common_step(batch, 'test')\n",
        "\n",
        "    def predict_step(self, batch: Dict[str, torch.Tensor], batch_idx: Optional[int] = None, dataloader_idx: int = 0):\n",
        "        x     = batch['x_demand']\n",
        "        x_reg = batch.get('x_regressors', None)\n",
        "        y_reg = batch.get('y_regressors', None)\n",
        "        return self(x, x_regressors=x_reg, y_demand=None, y_regressors=y_reg)\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        return torch.optim.Adam(self.parameters(), lr=self.hparams.learning_rate)\n"
      ],
      "metadata": {
        "id": "8PHs4BSA9D6k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Modelo de pronóstico basado en LSTM que hereda de BaseForecaster.\n",
        "class LSTMForecaster(BaseForecaster):\n",
        "    def __init__(self, input_dim=1, regressor_dim=3, hidden_dim=64,\n",
        "                 num_layers=2, dropout=0.1, forecast_length=6, learning_rate=1e-3):\n",
        "        super().__init__(learning_rate=learning_rate)\n",
        "        self.save_hyperparameters()\n",
        "        self.lstm = nn.LSTM(input_size=input_dim + regressor_dim,\n",
        "                            hidden_size=hidden_dim,\n",
        "                            num_layers=num_layers,\n",
        "                            batch_first=True,\n",
        "                            dropout=dropout)\n",
        "        self.hidden_to_output = nn.Linear(hidden_dim, 1)\n",
        "\n",
        "    def forward(self, x_demand, x_regressors=None, y_demand=None, y_regressors=None):\n",
        "        B, L, _ = x_demand.shape\n",
        "        H = self.hparams.forecast_length\n",
        "        R = self.hparams.regressor_dim\n",
        "        if x_regressors is None:\n",
        "            x_regressors = torch.zeros(B, L, R, device=x_demand.device)\n",
        "        enc_in = torch.cat([x_demand, x_regressors], dim=-1)\n",
        "        if y_demand is not None:\n",
        "            # Teacher forcing: y desplazada una posición (primer paso en cero)\n",
        "            y_shift = torch.zeros_like(y_demand)\n",
        "            y_shift[:, 1:, :] = y_demand[:, :-1, :]\n",
        "            if y_regressors is None:\n",
        "                y_regressors = torch.zeros(B, H, R, device=x_demand.device)\n",
        "            dec_in = torch.cat([y_shift, y_regressors], dim=-1)\n",
        "            seq_in = torch.cat([enc_in, dec_in], dim=1)\n",
        "            out, _ = self.lstm(seq_in)\n",
        "            return self.hidden_to_output(out[:, -H:, :])\n",
        "        # Inferencia: delegamos a predict_step para autoregresivo\n",
        "        return self.predict_step({'x_demand': x_demand, 'x_regressors': x_regressors, 'y_regressors': y_regressors}, None)\n",
        "\n",
        "    def predict_step(self, batch, batch_idx=None, dataloader_idx=0):\n",
        "        # Generación autoregresiva: un paso a la vez, retroalimentando predicción previa\n",
        "        x = batch['x_demand']; xr = batch.get('x_regressors'); yr = batch.get('y_regressors')\n",
        "        B, L, _ = x.shape; H = self.hparams.forecast_length; R = self.hparams.regressor_dim\n",
        "        if xr is None: xr = torch.zeros(B, L, R, device=x.device)\n",
        "        if yr is None: yr = torch.zeros(B, H, R, device=x.device)\n",
        "        out, (h, c) = self.lstm(torch.cat([x, xr], dim=-1))\n",
        "        preds = []; prev_y = x[:, -1:, :]\n",
        "        for t in range(H):\n",
        "            step_in = torch.cat([prev_y, yr[:, t:t+1, :]], dim=-1)\n",
        "            out, (h, c) = self.lstm(step_in, (h, c))\n",
        "            pred_t = self.hidden_to_output(out)\n",
        "            preds.append(pred_t); prev_y = pred_t\n",
        "        return torch.cat(preds, dim=1)"
      ],
      "metadata": {
        "id": "gFHr2Km29Q0G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "logger = CSVLogger(save_dir='/mnt/data', name='lstm_destinos_logs_inflacion')\n",
        "\n",
        "results = []     # para MAE/MSE por destino\n",
        "val_rows = []    # Tabla 1: validación real vs pred\n",
        "series_rows = [] # Tabla 2: histórico + forecast\n",
        "\n",
        "# Bucle de entrenamiento, validación y generación de forecast por destino\n",
        "for (mon, des) in DESTINOS_SELECCIONADOS:\n",
        "    dsd = df_pct[(df_pct['Moneda'] == mon) & (df_pct['Destino'] == des)].copy()\n",
        "    if dsd.empty:\n",
        "        print(f\"[AVISO] Sin datos para: ({mon}, {des}).\"); continue\n",
        "\n",
        "  # Ordena y deja solo columnas de fecha y porcentaje, con índice = Periodo\n",
        "\n",
        "    serie = dsd[['Periodo','porcentaje']].dropna().set_index('Periodo').sort_index()\n",
        "    if len(serie) < LOOKBACK + H + 5:\n",
        "        print(f\"[AVISO] Serie corta para: ({mon}, {des}). len={len(serie)}\"); continue\n",
        "\n",
        "    # Calcula regresores de calendario (mes_sin, mes_cos)\n",
        "    reg_month = month_sin_cos(serie.index)\n",
        "    infl_series = align_inflation_to_index(df_inf, serie.index)\n",
        "\n",
        "    n = len(serie)\n",
        "     # Toma 20% para validación\n",
        "    n_val = max(H, int(n*0.2))\n",
        "    train_y = serie.iloc[:n-n_val].copy()\n",
        "    valid_y = serie.iloc[n-n_val:].copy()\n",
        "\n",
        "    scaler_y = MinMaxScaler1D().fit(train_y['porcentaje'].values)\n",
        "    scaler_infl = MinMaxScaler1D().fit(infl_series[:len(train_y)])\n",
        "\n",
        "\n",
        "    y_tr = scaler_y.transform(train_y['porcentaje'].values)\n",
        "    y_va = scaler_y.transform(valid_y['porcentaje'].values)\n",
        "\n",
        "    infl_tr = scaler_infl.transform(infl_series[:len(train_y)])\n",
        "    infl_va = scaler_infl.transform(infl_series[len(train_y):])\n",
        "\n",
        "    reg_tr = np.column_stack([reg_month[:len(train_y)], infl_tr.reshape(-1,1)])\n",
        "    reg_va = np.column_stack([reg_month[len(train_y):], infl_va.reshape(-1,1)])\n",
        "\n",
        "    y_for_valid = np.concatenate([y_tr[-LOOKBACK:], y_va])\n",
        "    reg_for_valid = np.concatenate([reg_tr[-LOOKBACK:], reg_va])\n",
        "\n",
        "    X_tr, Y_tr, XR_tr, YR_tr, _ = build_windows_with_regs(y_tr, reg_tr, train_y.index, LOOKBACK, H)\n",
        "    X_va, Y_va, XR_va, YR_va, _ = build_windows_with_regs(\n",
        "        y_for_valid, reg_for_valid,\n",
        "        pd.Index([*train_y.index[-LOOKBACK:], *valid_y.index]), LOOKBACK, H\n",
        "    )\n",
        "    if len(X_tr) == 0 or len(X_va) == 0:\n",
        "        print(f\"[AVISO] Ventanas vacías para: ({mon}, {des}).\"); continue\n",
        "\n",
        "    # Crea el DataModule con los datos preparados\n",
        "    dm = TSDataModule(X_tr, Y_tr, XR_tr, YR_tr, X_va, Y_va, XR_va, YR_va, batch_size=BATCH_SIZE)\n",
        "    # Crea el modelo LSTM con hiperparámetros predefinidos\n",
        "    model = LSTMForecaster(input_dim=1, regressor_dim=3, hidden_dim=HIDDEN_DIM,\n",
        "                           num_layers=NUM_LAYERS, dropout=DROPOUT,\n",
        "                           forecast_length=H, learning_rate=LR)\n",
        "\n",
        "\n",
        "    early = EarlyStopping(monitor='val_mse', mode='min', patience=PATIENCE)\n",
        "    ckpt  = ModelCheckpoint(monitor='val_mse', mode='min', save_top_k=1)\n",
        "\n",
        "    # Entrenador Lightning\n",
        "    trainer = Trainer(max_epochs=MAX_EPOCHS, accelerator='auto', devices=1,\n",
        "                      logger=logger, callbacks=[early, ckpt], enable_progress_bar=False)\n",
        "    trainer.fit(model, dm.train_dataloader(), dm.val_dataloader())\n",
        "\n",
        "    # ----- Comparación validación (primer bloque) -----\n",
        "    val_loader = dm.val_dataloader()\n",
        "    batch = next(iter(val_loader))\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "       # Predice usando teacher forcing\n",
        "        y_hat = model(batch['x_demand'], batch.get('x_regressors'),\n",
        "                      batch['y_demand'], batch.get('y_regressors'))\n",
        "\n",
        "    val_dates = valid_y.index[:H]\n",
        "    y_true = batch['y_demand'].squeeze(-1).numpy()[0]\n",
        "    y_pred = y_hat.squeeze(-1).numpy()[0]\n",
        "    y_true_unscaled = scaler_y.inverse_transform(y_true)\n",
        "    y_pred_unscaled = scaler_y.inverse_transform(y_pred)\n",
        "\n",
        "# Métricas MAE y MSE en escala original\n",
        "    mae_val = mean_absolute_error(y_true_unscaled, y_pred_unscaled)\n",
        "    mse_val = mean_squared_error(y_true_unscaled, y_pred_unscaled)\n",
        "\n",
        "    results.append({'Moneda': mon, 'Destino': des, 'MAE_val': mae_val, 'MSE_val': mse_val})\n",
        "    print(f\"{mon} - {des} -> MAE_val={mae_val:.4f}, MSE_val={mse_val:.4f}\")\n",
        "\n",
        "    # Guardar filas tabla 1\n",
        "    for dt, yr, yp in zip(val_dates, y_true_unscaled, y_pred_unscaled):\n",
        "        val_rows.append({\n",
        "            'Moneda': mon,\n",
        "            'Destino': des,\n",
        "            'Fecha': dt,\n",
        "            'Real_valid': float(yr),\n",
        "            'Pred_valid': float(yp)\n",
        "        })\n",
        "\n",
        "    # ----- Forecast futuro H pasos -----\n",
        "    y_full_scaled = scaler_y.transform(serie['porcentaje'].values)\n",
        "    context_y  = y_full_scaled[-LOOKBACK:]\n",
        "    context_rm = reg_month[-LOOKBACK:, :]\n",
        "    context_in = scaler_infl.transform(infl_series[-LOOKBACK:])\n",
        "    context_xr = np.column_stack([context_rm, context_in.reshape(-1,1)])\n",
        "\n",
        "    last_date = serie.index.max()\n",
        "    future_idx = pd.date_range(last_date + pd.offsets.MonthEnd(1), periods=H, freq='M')\n",
        "    future_rm  = month_sin_cos(future_idx)\n",
        "    infl_future_raw = align_inflation_to_index(df_inf, future_idx)   # LVCF si no hay\n",
        "    infl_future_scaled = scaler_infl.transform(infl_future_raw)\n",
        "    future_regs = np.column_stack([future_rm, infl_future_scaled.reshape(-1,1)])\n",
        "\n",
        "    # Tensores para pasar al modelo en predict_step\n",
        "    x_batch  = torch.tensor(context_y).unsqueeze(0).unsqueeze(-1)\n",
        "    xr_batch = torch.tensor(context_xr).unsqueeze(0)\n",
        "    yr_batch = torch.tensor(future_regs).unsqueeze(0)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        preds_scaled = model.predict_step({'x_demand': x_batch,\n",
        "                                           'x_regressors': xr_batch,\n",
        "                                           'y_regressors': yr_batch}, None)\n",
        "    preds_scaled = preds_scaled.squeeze(0).squeeze(-1).cpu().numpy()\n",
        "    forecast_future = scaler_y.inverse_transform(preds_scaled)\n",
        "\n",
        "    # ----- Tabla 2: histórico + forecast -----\n",
        "    for dt, v in zip(serie.index, serie['porcentaje'].values):\n",
        "        series_rows.append({'Moneda': mon, 'Destino': des, 'Fecha': dt, 'Proporcion': float(v), 'Tipo': 'Historico'})\n",
        "    for dt, v in zip(future_idx, forecast_future):\n",
        "        series_rows.append({'Moneda': mon, 'Destino': des, 'Fecha': dt, 'Proporcion': float(v), 'Tipo': 'Forecast'})\n",
        "\n",
        "    # ----- Gráfico por destino -----\n",
        "    plt.figure(figsize=(9,5))\n",
        "    # Histórico\n",
        "    plt.plot(serie.index, serie['porcentaje'].values, label='Histórico')\n",
        "    # Validación real\n",
        "    plt.plot(val_dates, y_true_unscaled, label='Validación (real)')\n",
        "    # Pred (punteada con puntos)\n",
        "    plt.plot(val_dates, y_pred_unscaled, linestyle='--', marker='o', label='Predicción (val)')\n",
        "    # Forecast futuro (punteada con puntos)\n",
        "    plt.plot(future_idx, forecast_future, linestyle=':', marker='o', label='Forecast futuro')\n",
        "    plt.title(f'{mon} - {des} — Proporción Stage 2+3 / Total — H={H}')\n",
        "    plt.xlabel('Fecha'); plt.ylabel('Proporción')\n",
        "    plt.legend(); plt.show()\n",
        "\n",
        "# Construir tablas finales\n",
        "df_validacion = pd.DataFrame(val_rows).sort_values(['Moneda','Destino','Fecha']).reset_index(drop=True)\n",
        "df_serie_full = pd.DataFrame(series_rows).sort_values(['Moneda','Destino','Fecha','Tipo']).reset_index(drop=True)\n",
        "df_resultados = pd.DataFrame(results).sort_values(['Moneda','Destino']).reset_index(drop=True)\n",
        "\n"
      ],
      "metadata": {
        "id": "w5X_YODT9ZPJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Tabla 3 — Métricas por destino (MAE/MSE):\")\n",
        "display(df_resultados)"
      ],
      "metadata": {
        "id": "qLK38OCRPHKy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Tabla 1 — Comparación Validación (real vs. pred):\")\n",
        "display(df_validacion)\n",
        "\n"
      ],
      "metadata": {
        "id": "z4clTQnNJGtH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Tabla 2 — Serie completa (histórico + forecast):\")\n",
        "display(df_serie_full)"
      ],
      "metadata": {
        "id": "qYf4J54pM_L_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Modelo Transformer**"
      ],
      "metadata": {
        "id": "emm_dK-4nTVF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class TransformerForecaster(BaseForecaster):\n",
        "    def __init__(self, input_dim=1, regressor_dim=3, hidden_dim=64, nhead=4,\n",
        "                 num_layers=2, dropout=0.1, forecast_length=6, learning_rate=1e-3):\n",
        "        super().__init__(learning_rate=learning_rate)\n",
        "        self.save_hyperparameters() # Guarda los hiperparámetros automáticamente (útil para reproducibilidad y logging)\n",
        "\n",
        "# Capa de codificación de Transformer\n",
        "        encoder_layer = nn.TransformerEncoderLayer(\n",
        "            d_model=hidden_dim, nhead=nhead, dropout=dropout, batch_first=True\n",
        "        )\n",
        "        self.encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
        "        self.input_projection = nn.Linear(input_dim + regressor_dim, hidden_dim)\n",
        "        self.decoder = nn.Linear(hidden_dim, 1) # Capa lineal final para mapear la salida del transformer a un único valor\n",
        "\n",
        "    def forward(self, x_demand, x_regressors=None, y_demand=None, y_regressors=None):\n",
        "        B, L, _ = x_demand.shape\n",
        "        H = self.hparams.forecast_length\n",
        "        R = self.hparams.regressor_dim\n",
        "\n",
        "        if x_regressors is None:  # Si no se pasan regresores de entrada, inicializa con ceros\n",
        "            x_regressors = torch.zeros(B, L, R, device=x_demand.device)\n",
        "        enc_in = torch.cat([x_demand, x_regressors], dim=-1)  # Une demanda y regresores en la dimensión de features\n",
        "        enc_in = self.input_projection(enc_in)\n",
        "        memory = self.encoder(enc_in)\n",
        "\n",
        "        if y_demand is not None:\n",
        "            if y_regressors is None:\n",
        "                y_regressors = torch.zeros(B, H, R, device=x_demand.device)\n",
        "            y_shift = torch.zeros_like(y_demand)\n",
        "            y_shift[:, 1:, :] = y_demand[:, :-1, :]\n",
        "            dec_in = torch.cat([y_shift, y_regressors], dim=-1)\n",
        "            dec_in = self.input_projection(dec_in)\n",
        "            out = self.encoder(dec_in)\n",
        "            return self.decoder(out)\n",
        "\n",
        "        return self.predict_step({'x_demand': x_demand, 'x_regressors': x_regressors, 'y_regressors': y_regressors}, None)\n",
        "\n",
        "    def predict_step(self, batch, batch_idx=None, dataloader_idx=0): # Extrae entradas y regresores\n",
        "        x = batch['x_demand']\n",
        "        xr = batch.get('x_regressors')\n",
        "        yr = batch.get('y_regressors')\n",
        "        B, L, _ = x.shape\n",
        "        H = self.hparams.forecast_length # longitud del horizonte de predicción\n",
        "        R = self.hparams.regressor_dim   # cantidad de regresores\n",
        "\n",
        "        if xr is None:\n",
        "            xr = torch.zeros(B, L, R, device=x.device)\n",
        "        if yr is None:\n",
        "            yr = torch.zeros(B, H, R, device=x.device)\n",
        "\n",
        "        # Combina demanda y regresores de entrada y proyecta\n",
        "        enc_in = torch.cat([x, xr], dim=-1)\n",
        "        enc_in = self.input_projection(enc_in)\n",
        "        memory = self.encoder(enc_in)\n",
        "\n",
        "        preds = []\n",
        "        prev_y = torch.zeros(B, 1, 1, device=x.device)\n",
        "\n",
        "        # Predicción autoregresiva paso a paso\n",
        "        for t in range(H):\n",
        "            dec_in = torch.cat([prev_y, yr[:, t:t+1, :]], dim=-1)\n",
        "            dec_in = self.input_projection(dec_in)\n",
        "            out = self.encoder(dec_in)\n",
        "            pred_t = self.decoder(out)\n",
        "            preds.append(pred_t)\n",
        "            prev_y = pred_t\n",
        "        return torch.cat(preds, dim=1)\n"
      ],
      "metadata": {
        "id": "UkpYzLjUn89K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Entrenamiento y forecast con TransformerForecaster (incluyendo inflación)\n",
        "\n",
        "logger_trf = CSVLogger(save_dir='/mnt/data', name='trf_inflacion')\n",
        "\n",
        "metrics_trf = []\n",
        "val_trf = []\n",
        "series_rows_trf = []\n",
        "\n",
        "for (mon, des) in DESTINOS_SELECCIONADOS:\n",
        "    dsd = df_pct[(df_pct['Moneda']==mon) & (df_pct['Destino']==des)]\n",
        "    if dsd.empty:\n",
        "        print(f\"[TRF] Sin datos para {mon}-{des}\");\n",
        "        continue\n",
        "\n",
        "    # Serie ordenada por fecha con índice mensual\n",
        "    serie = dsd[['Periodo','porcentaje']].dropna().set_index('Periodo').sort_index()\n",
        "    if len(serie) < LOOKBACK + H + 5:\n",
        "        print(f\"[TRF] Serie corta para {mon}-{des} (len={len(serie)})\")\n",
        "        continue\n",
        "    #Regresores: estacionales (mes_sin, mes_cos) + inflación alineada al índice\n",
        "    reg_month = month_sin_cos(serie.index)\n",
        "    infl_vals = align_inflation_to_index(df_inf, serie.index)\n",
        "\n",
        "    #Split train/valid (valid ~ 20% o al menos H) ---\n",
        "    n = len(serie); n_val = max(H, int(n*0.2))\n",
        "    train_y = serie.iloc[:n-n_val]; valid_y = serie.iloc[n-n_val:]\n",
        "\n",
        "    sc_y = MinMaxScaler1D().fit(train_y['porcentaje'].values)\n",
        "    sc_in = MinMaxScaler1D().fit(infl_vals[:len(train_y)])\n",
        "\n",
        "    y_tr = sc_y.transform(train_y['porcentaje'].values)\n",
        "    y_va = sc_y.transform(valid_y['porcentaje'].values)\n",
        "    in_tr = sc_in.transform(infl_vals[:len(train_y)])\n",
        "    in_va = sc_in.transform(infl_vals[len(train_y):])\n",
        "\n",
        "\n",
        "    # Matrices de regresores\n",
        "    reg_tr = np.column_stack([reg_month[:len(train_y)], in_tr.reshape(-1,1)])\n",
        "    reg_va = np.column_stack([reg_month[len(train_y):], in_va.reshape(-1,1)])\n",
        "\n",
        "    y_for_valid   = np.concatenate([y_tr[-LOOKBACK:],  y_va])\n",
        "    reg_for_valid = np.vstack([reg_tr[-LOOKBACK:], reg_va])\n",
        "\n",
        "\n",
        "    # Armado de ventanas para entrenamiento\n",
        "    X_tr, Y_tr, XR_tr, YR_tr, _ = build_windows_with_regs(y_tr, reg_tr, train_y.index, LOOKBACK, H)\n",
        "\n",
        "    # Validación: necesitamos concatenar los últimos LOOKBACK índices de entrenamiento + los de validación\n",
        "    if len(train_y) < LOOKBACK:\n",
        "      print(f\"[TRF] train_y demasiado corto para {mon}-{des}, len={len(train_y)}\")\n",
        "      continue\n",
        "\n",
        "    idx_valid = pd.Index([*train_y.index[-LOOKBACK:], *valid_y.index])\n",
        "    X_va, Y_va, XR_va, YR_va, _ = build_windows_with_regs(y_for_valid, reg_for_valid, idx_valid, LOOKBACK, H)\n",
        "\n",
        "    # Control adicional por si alguna ventana queda vacía\n",
        "    if len(X_tr) == 0 or len(X_va) == 0:\n",
        "      print(f\"[TRF] Ventanas vacías para {mon}-{des}\");\n",
        "      continue\n",
        "    #DataModule + Modelo\n",
        "    dm = TSDataModule(X_tr, Y_tr, XR_tr, YR_tr, X_va, Y_va, XR_va, YR_va, batch_size=BATCH_SIZE)\n",
        "    model = TransformerForecaster(input_dim=1, regressor_dim=3, hidden_dim=HIDDEN_DIM, nhead=NHEAD,\n",
        "                                  num_layers=NUM_LAYERS, dropout=DROPOUT, forecast_length=H, learning_rate=LR)\n",
        "\n",
        "\n",
        "    # Entrenamiento con early stopping y checkpoint por val_mse\n",
        "    trainer = Trainer(max_epochs=MAX_EPOCHS, accelerator='auto', devices=1,\n",
        "                      logger=logger_trf, callbacks=[EarlyStopping(monitor='val_mse', patience=PATIENCE),\n",
        "                                                    ModelCheckpoint(monitor='val_mse')],\n",
        "                      enable_progress_bar=False)\n",
        "    trainer.fit(model, dm.train_dataloader(), dm.val_dataloader())\n",
        "\n",
        "     # Validación: predicción del primer batch de validación\n",
        "    batch = next(iter(dm.val_dataloader()))\n",
        "    with torch.no_grad():\n",
        "        yhat = model(batch['x_demand'], batch['x_regressors'], batch['y_demand'], batch['y_regressors'])\n",
        "    val_dates = valid_y.index[:H]\n",
        "    y_true = sc_y.inverse_transform(batch['y_demand'].squeeze(-1).numpy()[0])\n",
        "    y_pred = sc_y.inverse_transform(yhat.squeeze(-1).numpy()[0])\n",
        "\n",
        "    # Métricas por destino\n",
        "    mae = mean_absolute_error(y_true, y_pred)\n",
        "    mse = mean_squared_error(y_true, y_pred)\n",
        "    metrics_trf.append({'Moneda':mon,'Destino':des,'MAE_val':mae,'MSE_val':mse})\n",
        "\n",
        "    for dt, yr, yp in zip(val_dates, y_true, y_pred):\n",
        "        val_trf.append({'Moneda':mon,'Destino':des,'Fecha':dt,'Real_valid':float(yr),'Pred_TRF':float(yp)})\n",
        "\n",
        "    # Forecast futuro (Transformer)\n",
        "    context_y = sc_y.transform(serie['porcentaje'].values[-LOOKBACK:])\n",
        "    context_xr = np.column_stack([reg_month[-LOOKBACK:], infl_vals[-LOOKBACK:].reshape(-1,1)])\n",
        "    future_idx = pd.date_range(serie.index.max() + pd.offsets.MonthEnd(1), periods=H, freq='M')\n",
        "    # Regresores futuros: estacionales del futuro + inflación futura alineada\n",
        "    future_regs = month_sin_cos(future_idx)\n",
        "    future_infl = align_inflation_to_index(df_inf, future_idx)\n",
        "    future_infl = sc_in.transform(future_infl)\n",
        "    future_xr = np.column_stack([future_regs, future_infl.reshape(-1,1)])\n",
        "\n",
        "    # Tensores para el modelo\n",
        "    x_batch  = torch.tensor(context_y).unsqueeze(0).unsqueeze(-1).float()\n",
        "    xr_batch = torch.tensor(context_xr).unsqueeze(0).float()\n",
        "    yr_batch = torch.tensor(future_xr).unsqueeze(0).float()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        forecast = model.predict_step({'x_demand': x_batch,\n",
        "                                       'x_regressors': xr_batch,\n",
        "                                       'y_regressors': yr_batch}, None)\n",
        "\n",
        "    forecast = forecast.squeeze(0).squeeze(-1).cpu().numpy()\n",
        "    forecast_unscaled = sc_y.inverse_transform(forecast)\n",
        "\n",
        "    # Guardar histórico + forecast\n",
        "    for dt, v in zip(serie.index, serie['porcentaje'].values):\n",
        "        series_rows_trf.append({'Moneda': mon, 'Destino': des, 'Fecha': dt, 'Proporcion': float(v), 'Tipo': 'Historico'})\n",
        "    for dt, v in zip(future_idx, forecast_unscaled):\n",
        "        series_rows_trf.append({'Moneda': mon, 'Destino': des, 'Fecha': dt, 'Proporcion': float(v), 'Tipo': 'Forecast'})\n",
        "\n",
        "    # Gráfico por destino\n",
        "    plt.figure(figsize=(9,5))\n",
        "    plt.plot(serie.index, serie['porcentaje'].values, label='Histórico')\n",
        "    plt.plot(val_dates, y_true, label='Validación (real)')\n",
        "    plt.plot(val_dates, y_pred, linestyle='--', marker='x', label='Pred TRF (val)')\n",
        "    plt.plot(future_idx, forecast_unscaled, linestyle=':', marker='x', label='Forecast TRF')\n",
        "    plt.title(f'{mon} - {des} — Transformer')\n",
        "    plt.xlabel('Fecha'); plt.ylabel('Proporción'); plt.legend(); plt.show()\n",
        "\n",
        "df_metrics_trf = pd.DataFrame(metrics_trf).sort_values(['Moneda','Destino']).reset_index(drop=True)\n",
        "df_val_trf     = pd.DataFrame(val_trf).sort_values(['Moneda','Destino','Fecha']).reset_index(drop=True)\n",
        "df_full_trf    = pd.DataFrame(series_rows_trf).sort_values(['Moneda','Destino','Fecha']).reset_index(drop=True)\n",
        "\n",
        "print(\"Tabla Transformer — Métricas (MAE/MSE):\")\n",
        "display(df_metrics_trf)\n",
        "print(\"Tabla Transformer — Validación (Real vs Pred_TRF):\")\n",
        "display(df_val_trf.head(30))\n",
        "print(\"Tabla Transformer — Serie completa (histórico + forecast):\")\n",
        "display(df_full_trf.head(30))"
      ],
      "metadata": {
        "id": "ycsjgrOYv4iF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}